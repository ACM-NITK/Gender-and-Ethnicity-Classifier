{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport glob\nimport numpy as np\nfrom PIL import Image\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow import reduce_mean\nfrom tensorflow.train import AdamOptimizer as adam\nfrom tensorflow.nn import sigmoid_cross_entropy_with_logits as loss\nfrom tensorflow.layers import dense, batch_normalization, conv2d_transpose, conv2d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the UTKFace Dataset and resizing the images\n\nimage_ids = glob.glob('../input/utkface_aligned_cropped/UTKFace/*')\n\ncrop = (30, 55, 150, 175)\nimages = [np.array((Image.open(i).crop(crop)).resize((64,64))) for i in image_ids]\n\nfor i in range(len(images)):\n    images[i] = ((images[i] - images[i].min())/(255 - images[i].min()))\n    images[i] = images[i]*2-1\n    \nimages = np.array(images)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def inputs(real_dim, noise_dim):\n    \n    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='input_real')\n    inputs_noise = tf.placeholder(tf.float32, (None, noise_dim), name='input_noise')\n    \n    return inputs_real, inputs_noise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7463952b96a7f35c73d81578d2390587cdad04f"},"cell_type":"code","source":"#Generator Function\n\ndef generator(noise, reuse=False, alpha=0.2, training=True):\n    \n    with tf.variable_scope('generator', reuse=reuse):\n        \n        x = dense(noise, 4*4*512)\n        x = tf.reshape(x, (-1, 4, 4, 512))\n        x = batch_normalization(x, training=training)\n        x = tf.maximum(alpha*x, x)\n        \n        x = conv2d_transpose(x, 256, 5, 2, padding='same')\n        x = batch_normalization(x, training=training)\n        x = tf.maximum(alpha*x, x)\n        \n        x = conv2d_transpose(x, 128, 5, 2, padding='same')\n        x = batch_normalization(x, training=training)\n        x = tf.maximum(alpha*x, x)\n        \n        x = conv2d_transpose(x, 64, 5, 2, padding='same')\n        x = batch_normalization(x, training=training)\n        x = tf.maximum(alpha*x, x)\n        \n        logits = conv2d_transpose(x, 3, 5, 2, padding='same')\n        out = tf.tanh(logits)\n        \n        return out, logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5ec5902633650fa48a6d4c675a3cfec964eed6e"},"cell_type":"code","source":"#Discriminator Function\n\ndef discriminator(x, reuse=False, alpha=0.2, training=True):\n    \n    with tf.variable_scope('discriminator', reuse=reuse):\n        \n        x = conv2d(x, 32, 5, 2, padding='same')\n        x = tf.maximum(alpha*x, x)\n        \n        x = conv2d(x, 64, 5, 2, padding='same')\n        x = batch_normalization(x, training=training)\n        x = tf.maximum(alpha*x, x)\n        \n        x = conv2d(x, 128, 5, 2, padding='same')\n        x = batch_normalization(x, training=training)\n        x = tf.maximum(alpha*x, x)\n        \n        x = conv2d(x, 256, 5, 2, padding='same')\n        x = batch_normalization(x, training=training)\n        x = tf.maximum(alpha*x, x)        \n        \n        flatten = tf.reshape(x, (-1, 4*4*256))\n        logits = dense(flatten, 1)\n        out = tf.sigmoid(logits)\n        \n        return out, logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df80af0b4285c9df0e5d1376d7786a0694d62ce0"},"cell_type":"code","source":"# hyperparameters\n\nbeta1 = 0.5\nalpha = 0.2\nsmooth = 0.9\nnoise_size = 200\nlearning_rate = 0.0002\ninput_shape = (64,64,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3fa8c75a8d714929c155ab3dff87c1bb60264f7"},"cell_type":"code","source":"# building the graph\n\ntf.reset_default_graph()\n\ninput_real, input_noise = inputs(input_shape, noise_size)\n\ngen_noise, gen_logits = generator(input_noise)\n\ndis_out_real, dis_logits_real = discriminator(input_real)\ndis_out_fake, dis_logits_fake = discriminator(gen_noise, reuse=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1af5a4236604a592e9d3671fc92111adfd9d5c6"},"cell_type":"code","source":"# defining losses\n\nshape = dis_logits_real\n\ndis_loss_real = reduce_mean(loss(logits=dis_logits_real, labels=tf.ones_like(shape*smooth)))\n\ndis_loss_fake = reduce_mean(loss(logits=dis_logits_fake, labels=tf.zeros_like(shape)))                             \n\ngen_loss = reduce_mean(loss(logits=dis_logits_fake, labels=tf.ones_like(shape*smooth)))\n\ndis_loss = dis_loss_real + dis_loss_fake","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ef1802171fc2e95a502d0d0c0b044cc35347afe"},"cell_type":"code","source":"# defining optimizers\n\ntotal_vars = tf.trainable_variables()\n\ndis_vars = [var for var in total_vars if var.name[0] == 'd']\ngen_vars = [var for var in total_vars if var.name[0] == 'g']\n \ndis_opt = adam(learning_rate=learning_rate, beta1=beta1).minimize(dis_loss, var_list=dis_vars)\ngen_opt = adam(learning_rate=learning_rate, beta1=beta1).minimize(gen_loss, var_list=gen_vars)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e9d1d7f7af28a1a93d4c7363a3cf327aaaa9836"},"cell_type":"code","source":"#Function to view the image samples\n\ndef view_samples(epoch, samples, nrows, ncols, figsize=(5,5)):\n    \n    fig, axes = plt.subplots(figsize=figsize, nrows=nrows, ncols=ncols)\n    \n    for ax, img in zip(axes.flatten(), samples[epoch]):\n        \n        ax.axis('off')\n        # img = (((img+1)/2)*255).astype(np.uint8)\n        img = ((img - img.min())*255 / (img.max() - img.min())).astype(np.uint8)\n        im = ax.imshow(img)\n   \n    plt.subplots_adjust(wspace=0, hspace=0)\n    return fig, axes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e5d1f69e53e414959ef1c75108921f7e7c240db"},"cell_type":"code","source":"#Training the GAN\n\nbatch_size = 128\nepochs = 100\niters = len(image_ids)//batch_size\nsaver = tf.train.Saver(var_list = gen_vars)\n\nwith tf.Session() as sess:\n    \n    sess.run(tf.global_variables_initializer())\n    \n    for e in range(epochs):\n                \n        for i in range(iters-1):\n            \n            batch_images = images[i*batch_size:(i+1)*batch_size]\n            batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n            \n            sess.run(dis_opt, feed_dict={input_real: batch_images, input_noise: batch_noise})\n            sess.run(gen_opt, feed_dict={input_real: batch_images, input_noise: batch_noise})\n            \n            if i%50 == 0:\n                print(\"Epoch {}/{}...\".format(e+1, epochs), \"Batch No {}/{}\".format(i+1, iters))\n                \n        loss_dis = sess.run(dis_loss, {input_noise: batch_noise, input_real: batch_images})\n        loss_gen = gen_loss.eval({input_real: batch_images, input_noise: batch_noise})\n            \n        print(\"Epoch {}/{}...\".format(e+1, epochs),\"Discriminator Loss: {:.4f}...\".format(loss_dis),\n              \"Generator Loss: {:.4f}\".format(loss_gen))      \n        \n        sample_noise = np.random.uniform(-1, 1, size=(8, noise_size))\n        gen_samples = sess.run(generator(input_noise, reuse=True, alpha=alpha),\n                               feed_dict={input_noise: sample_noise})\n\n        view_samples(-1, gen_samples, 2, 4, (10,5))\n        plt.show()\n        saver.save(sess, './checkpoints/generator.ckpt')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}